{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "647ea222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all heading tags: \n",
      "\n",
      "\n",
      "<h1 class=\"firstHeading\" id=\"firstHeading\">Main Page</h1>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-tfa-h2\"><span id=\"From_today.27s_featured_article\"></span><span class=\"mw-headline\" id=\"From_today's_featured_article\">From today's featured article</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-dyk-h2\"><span class=\"mw-headline\" id=\"Did_you_know_...\">Did you know ...</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-itn-h2\"><span class=\"mw-headline\" id=\"In_the_news\">In the news</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-otd-h2\"><span class=\"mw-headline\" id=\"On_this_day\">On this day</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-tfp-h2\"><span id=\"Today.27s_featured_picture\"></span><span class=\"mw-headline\" id=\"Today's_featured_picture\">Today's featured picture</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-other\"><span class=\"mw-headline\" id=\"Other_areas_of_Wikipedia\">Other areas of Wikipedia</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-sister\"><span id=\"Wikipedia.27s_sister_projects\"></span><span class=\"mw-headline\" id=\"Wikipedia's_sister_projects\">Wikipedia's sister projects</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-lang\"><span class=\"mw-headline\" id=\"Wikipedia_languages\">Wikipedia languages</span></h2>\n",
      "\n",
      "<h2>Navigation menu</h2>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-personal-label\"><span>Personal tools</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-namespaces-label\"><span>Namespaces</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-variants-label\"><span>Variants</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-views-label\"><span>Views</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-cactions-label\"><span>More</span>\n",
      "</h3>\n",
      "\n",
      "<h3>\n",
      "<label for=\"searchInput\">Search</label>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-navigation-label\"><span>Navigation</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-interaction-label\"><span>Contribute</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-tb-label\"><span>Tools</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-coll-print_export-label\"><span>Print/export</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-wikibase-otherprojects-label\"><span>In other projects</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-lang-label\"><span>Languages</span>\n",
      "</h3>\n"
     ]
    }
   ],
   "source": [
    "#1. Write a python program to display all the header tags from‘en.wikipedia.org/wiki/Main_Page’.\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "page=requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "soup=BeautifulSoup(page.content)\n",
    "heading=soup.find_all(['h1','h2','h3','h4','h5','h6'])\n",
    "print('all heading tags: \\n',*heading,sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "9b15629f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "                                   Name Release Year Rating\n",
      "0              The Shawshank Redemption         1994    9.3\n",
      "1                         The Godfather         1972    9.2\n",
      "2                The Godfather: Part II         1974      9\n",
      "3                       The Dark Knight         2008      9\n",
      "4                          12 Angry Men         1957      9\n",
      "..                                  ...          ...    ...\n",
      "95                   North by Northwest         1959    8.3\n",
      "96                   A Clockwork Orange         1971    8.3\n",
      "97                               Snatch         2000    8.3\n",
      "98  Le fabuleux destin d'Amélie Poulain         2001    8.3\n",
      "99                              The Kid         1921    8.3\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#2. Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. Name, IMDB rating, Year of release).\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "name=requests.get('https://www.imdb.com/list/ls091520106/')\n",
    "print(name)\n",
    "soup=BeautifulSoup(name.content)\n",
    "Name=soup.find_all('h3',class_='lister-item-header')\n",
    "Name_list=[]\n",
    "for i in Name:\n",
    "    for j in i.find_all('a'):\n",
    "        Name_list.append(j.text.replace(\"\\n\",\"\")) \n",
    "rating=soup.find_all('div',class_=\"ipl-rating-star small\")\n",
    "rating_list=[]\n",
    "for i in rating:\n",
    "    for j in i.find_all('span',class_='ipl-rating-star__rating'):\n",
    "        rating_list.append(j.text)\n",
    "release=soup.find_all('span',class_=\"lister-item-year text-muted unbold\")\n",
    "release_list=[]\n",
    "for i in release:\n",
    "    release_list.append(i.text.replace('(','').replace(')',''))\n",
    "\n",
    "Movies_list=pd.DataFrame({})\n",
    "Movies_list['Name']=Name_list\n",
    "Movies_list['Release Year']=release_list\n",
    "Movies_list['Rating']=rating_list\n",
    "\n",
    "print(Movies_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "baf41787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "                      Name Release Year Rating\n",
      "0             Black Friday         2004    8.5\n",
      "1                   Pyaasa         1957    8.5\n",
      "2                  Golmaal         1979    8.5\n",
      "3                 3 Idiots         2009    8.4\n",
      "4         Taare Zameen Par         2007    8.4\n",
      "..                     ...          ...    ...\n",
      "95                Rangeela         1995    7.5\n",
      "96           Ek Hasina Thi         2004    7.5\n",
      "97  Qayamat Se Qayamat Tak         1988    7.5\n",
      "98            Socha Na Tha         2005    7.4\n",
      "99                   Gunda         1998    7.3\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#3. Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. Name, IMDB rating, Year of release).\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "name=requests.get('https://www.imdb.com/list/ls009997493/?sort=user_rating,desc&st_dt=&mode=detail&page=1')\n",
    "print(name)\n",
    "soup=BeautifulSoup(name.content)\n",
    "Name=soup.find_all('h3',class_='lister-item-header')\n",
    "Name_list=[]\n",
    "for i in Name:\n",
    "    for j in i.find_all('a'):\n",
    "        Name_list.append(j.text.replace(\"\\n\",\"\"))\n",
    "rating=soup.find_all('div',class_=\"ipl-rating-star small\")\n",
    "rating_list=[]\n",
    "for i in rating:\n",
    "    for j in i.find_all('span',class_='ipl-rating-star__rating'):\n",
    "        rating_list.append(j.text)\n",
    "release=soup.find_all('span',class_=\"lister-item-year text-muted unbold\")\n",
    "release_list=[]\n",
    "for i in release:\n",
    "    release_list.append(i.text.replace('(','').replace(')',''))\n",
    "\n",
    "Movies_list=pd.DataFrame({})\n",
    "Movies_list['Name']=Name_list\n",
    "Movies_list['Release Year']=release_list\n",
    "Movies_list['Rating']=rating_list\n",
    "\n",
    "print(Movies_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "3fc59e12",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "                          Book Name  \\\n",
      "0                       The Maidens   \n",
      "1                         The Guide   \n",
      "2  The Love Songs of W.E.B. Du Bois   \n",
      "3                          Einstein   \n",
      "4         A Duke Worth Fighting For   \n",
      "\n",
      "                                              Author  \\\n",
      "0  Alex Michaelides, Louise Brealey, Kobna Holdbr...   \n",
      "1                                       Peter Heller   \n",
      "2                            Honorée Fanonne Jeffers   \n",
      "3                                    Torben Kuhlmann   \n",
      "4                                  Christina Britton   \n",
      "\n",
      "                                      Genre  \\\n",
      "0     Audio / Mystery & Suspense / Suspense   \n",
      "1  Fiction / Speculative Fiction / Thriller   \n",
      "2              Fiction / Historical Fiction   \n",
      "3      Children's / Children's Picture Book   \n",
      "4              Romance / Historical Romance   \n",
      "\n",
      "                                              Review  \n",
      "0  Actors Louise Brealey and Kobna Holdbrook-Smit...  \n",
      "1  The Guide is a glorious getaway in every sense...  \n",
      "2  Honorée Fanonne Jeffers weaves an epic ancestr...  \n",
      "3  Author-illustrator Torben Kuhlmann explores th...  \n",
      "4                                                     \n"
     ]
    }
   ],
   "source": [
    "#4. Write a python program to scrap book name, author name, genre and book review of any 5 books from ‘www.bookpage.com’\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "page=requests.get('https://bookpage.com/reviews')\n",
    "print(page)\n",
    "soup=BeautifulSoup(page.content)\n",
    "name=soup.find_all('h4',class_='italic')\n",
    "Name_list=[]\n",
    "for i in name:\n",
    "    for j in i.find_all('a'):\n",
    "        Name_list.append(j.text.replace(\"\\n\",\"\").replace(' ★ ',''))\n",
    "author=soup.find_all('p',class_=\"sans bold\")\n",
    "Author=[]\n",
    "for i in author:\n",
    "    Author.append(i.text.replace('\\n',''))\n",
    "genre=soup.find_all('p',class_=\"genre-links hidden-phone\")\n",
    "Genre=[]\n",
    "for i in genre:\n",
    "    Genre.append(i.text.replace('\\n',''))\n",
    "review=soup.find_all('p',class_=\"excerpt\")\n",
    "Review=[]\n",
    "for i in review:\n",
    "    Review.append(i.text.replace('\\n',''))\n",
    "Book_list=pd.DataFrame({})\n",
    "Book_list['Book Name']=Name_list[:5]\n",
    "Book_list['Author']=Author[:5]\n",
    "Book_list['Genre']=Genre[:5]\n",
    "Book_list['Review']=Review[:5]\n",
    "\n",
    "print(Book_list)\n",
    "#Book_list.to_excel('book.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "d5c117bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ODI teams in men’s cricket: \n",
      "            Name Matches Points Rating\n",
      "0   New Zealand      17  2,054    121\n",
      "1       England      32  3,793    119\n",
      "2     Australia      28  3,244    116\n",
      "3         India      32  3,624    113\n",
      "4  South Africa      22  2,267    103\n",
      "5      Pakistan      27  2,524     93\n",
      "6    Bangladesh      29  2,639     91\n",
      "7   West Indies      30  2,523     84\n",
      "8     Sri Lanka      29  2,303     79\n",
      "9   Afghanistan      17  1,054     62\n",
      "\n",
      "\n",
      "Top 10 ODI Batsman in men’s cricket: \n",
      "               Name Team Rank\n",
      "0       Babar Azam  PAK  873\n",
      "1      Virat Kohli  IND  844\n",
      "2     Rohit Sharma  IND  813\n",
      "3      Ross Taylor   NZ  801\n",
      "4      Aaron Finch  AUS  779\n",
      "5   Jonny Bairstow  ENG  775\n",
      "6     David Warner  AUS  762\n",
      "7  Quinton de Kock   SA  758\n",
      "8        Shai Hope   WI  758\n",
      "9  Kane Williamson   NZ  754\n",
      "\n",
      "\n",
      "Top 10 ODI Bowler in men’s cricket: \n",
      "                   Name Team Rank\n",
      "0          Pat Cummins  AUS  908\n",
      "1  Ravichandran Ashwin  IND  848\n",
      "2          Tim Southee   NZ  824\n",
      "3       Josh Hazlewood  AUS  816\n",
      "4          Neil Wagner   NZ  810\n",
      "5       James Anderson  ENG  800\n",
      "6        Kagiso Rabada   SA  798\n",
      "7       Shaheen Afridi  PAK  783\n",
      "8         Jason Holder   WI  766\n",
      "9         Stuart Broad  ENG  764\n"
     ]
    }
   ],
   "source": [
    "# 5. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have toscrape:\n",
    "# i) Top 10 ODI teams in men’s cricket along with the records for matches, points andrating.\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "page=requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "soup=BeautifulSoup(page.content)\n",
    "name=soup.find_all('span',class_=\"u-hide-phablet\")\n",
    "Name=[]\n",
    "for i in name:\n",
    "    Name.append(i.text.replace('\\n',''))\n",
    "matches=soup.find_all('td',class_=\"rankings-block__banner--matches\")\n",
    "Matches=[]\n",
    "for i in matches:\n",
    "    Matches.append(i.text.replace('\\n',''))\n",
    "points=soup.find_all('td',class_=\"rankings-block__banner--points\")\n",
    "Points=[]\n",
    "for i in points:\n",
    "    Points.append(i.text.replace('\\n',''))\n",
    "matches=soup.find_all('td',class_=\"table-body__cell u-center-text\")\n",
    "newmatch=[]\n",
    "for i in matches:\n",
    "#     for j in matches:\n",
    "    Matches.append(i.text.replace('\\n',''))\n",
    "\n",
    "# print(Matches)\n",
    "for item in range(len(Matches)):\n",
    "    if item<=0:\n",
    "        newmatch.append(Matches[item])\n",
    "        \n",
    "    elif item%2==0:\n",
    "        Points.append(Matches[item])\n",
    "    else:\n",
    "        newmatch.append(Matches[item])\n",
    "rating=soup.find_all('td',class_=\"rankings-block__banner--rating u-text-right\")\n",
    "Rating=[]\n",
    "for i in rating:\n",
    "    Rating.append(i.text.replace('\\n','').replace(' ',''))\n",
    "rating1=soup.find_all('td',class_=\"table-body__cell u-text-right rating\")\n",
    "for i in rating1:\n",
    "    Rating.append(i.text.replace('\\n',''))\n",
    "ODI_ranking=pd.DataFrame({})\n",
    "ODI_ranking['Name']=Name[:10]\n",
    "ODI_ranking['Matches']=newmatch[:10]\n",
    "ODI_ranking['Points']=Points[:10]\n",
    "ODI_ranking['Rating']=Rating[:10]\n",
    "\n",
    "print('Top 10 ODI teams in men’s cricket: \\n',ODI_ranking)\n",
    "\n",
    "# ii) Top 10 ODI Batsmen in men along with the records of their team and rating.\n",
    "menpage=requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting')\n",
    "namesoup=BeautifulSoup(menpage.content)\n",
    "name=namesoup.find_all('div',class_=\"rankings-block__banner--name-large\")\n",
    "PName=[]\n",
    "for i in name:\n",
    "    PName.append(i.text.replace('\\n',''))\n",
    "name=namesoup.find_all('td',class_=\"table-body__cell rankings-table__name name\")\n",
    "for i in name:\n",
    "    for j in i('a'):\n",
    "        PName.append(j.text.replace('\\n',''))\n",
    "team=namesoup.find_all('div',class_=\"rankings-block__banner--nationality\")\n",
    "Pteam=[]\n",
    "for i in team:\n",
    "    Pteam.append(i.text.replace('\\n','').replace(' ',''))\n",
    "team=namesoup.find_all('span',class_=\"table-body__logo-text\")\n",
    "for i in team:\n",
    "    Pteam.append(i.text.replace('\\n',''))\n",
    "rank=namesoup.find_all('div',class_=\"rankings-block__banner--rating\")\n",
    "Prank=[]\n",
    "for i in rank:\n",
    "    Prank.append(i.text.replace('\\n','').replace(' ',''))\n",
    "rank=namesoup.find_all('td',class_=\"table-body__cell rating\")\n",
    "for i in rank:\n",
    "    Prank.append(i.text.replace('\\n',''))\n",
    "\n",
    "ODI_Player=pd.DataFrame({})\n",
    "ODI_Player['Name']=PName[:10]\n",
    "ODI_Player['Team']=Pteam[:10]\n",
    "ODI_Player['Rank']=Prank[:10]\n",
    "\n",
    "print('\\n\\nTop 10 ODI Batsman in men’s cricket: \\n',ODI_Player)\n",
    "\n",
    "# iii) Top 10 ODI bowlers along with the records of their team andrating.\n",
    "\n",
    "menpage=requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/test/bowling')\n",
    "namesoup=BeautifulSoup(menpage.content)\n",
    "name=namesoup.find_all('div',class_=\"rankings-block__banner--name-large\")\n",
    "PName=[]\n",
    "for i in name:\n",
    "    PName.append(i.text.replace('\\n',''))\n",
    "name=namesoup.find_all('td',class_=\"table-body__cell rankings-table__name name\")\n",
    "for i in name:\n",
    "    for j in i('a'):\n",
    "        PName.append(j.text.replace('\\n',''))\n",
    "team=namesoup.find_all('div',class_=\"rankings-block__banner--nationality\")\n",
    "Pteam=[]\n",
    "for i in team:\n",
    "    Pteam.append(i.text.replace('\\n','').replace(' ',''))\n",
    "team=namesoup.find_all('span',class_=\"table-body__logo-text\")\n",
    "for i in team:\n",
    "    Pteam.append(i.text.replace('\\n',''))\n",
    "rank=namesoup.find_all('div',class_=\"rankings-block__banner--rating\")\n",
    "Prank=[]\n",
    "for i in rank:\n",
    "    Prank.append(i.text.replace('\\n','').replace(' ',''))\n",
    "rank=namesoup.find_all('td',class_=\"table-body__cell rating\")\n",
    "for i in rank:\n",
    "    Prank.append(i.text.replace('\\n',''))\n",
    "\n",
    "ODI_bowler=pd.DataFrame({})\n",
    "ODI_bowler['Name']=PName[:10]\n",
    "ODI_bowler['Team']=Pteam[:10]\n",
    "ODI_bowler['Rank']=Prank[:10]\n",
    "\n",
    "print('\\n\\nTop 10 ODI Bowler in men’s cricket: \\n',ODI_bowler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "5e4f9012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ODI teams in women’s cricket: \n",
      "            Name Matches Points Rating\n",
      "0     Australia      18  2,955    164\n",
      "1       England      20  2,370    119\n",
      "2  South Africa      24  2,828    118\n",
      "3         India      23  2,535    110\n",
      "4   New Zealand      21  1,947     93\n",
      "5   West Indies      17  1,427     84\n",
      "6      Pakistan      20  1,496     75\n",
      "7    Bangladesh       5    306     61\n",
      "8     Sri Lanka      11    519     47\n",
      "9       Ireland       2     25     13\n",
      "\n",
      "\n",
      "Top 10 ODI Batsman in women’s cricket: \n",
      "                 Name Team Rank\n",
      "0        Mithali Raj  IND  762\n",
      "1        Lizelle Lee   SA  758\n",
      "2       Alyssa Healy  AUS  756\n",
      "3     Tammy Beaumont  ENG  754\n",
      "4    Stafanie Taylor   WI  736\n",
      "5        Meg Lanning  AUS  723\n",
      "6  Amy Satterthwaite   NZ  715\n",
      "7     Natalie Sciver  ENG  706\n",
      "8    Smriti Mandhana  IND  701\n",
      "9    Laura Wolvaardt   SA  683\n",
      "\n",
      "\n",
      "Top 10 ODI Bowler in women’s cricket: \n",
      "                 Name Team Rank\n",
      "0      Jess Jonassen  AUS  808\n",
      "1       Megan Schutt  AUS  762\n",
      "2     Marizanne Kapp   SA  747\n",
      "3     Shabnim Ismail   SA  717\n",
      "4     Jhulan Goswami  IND  694\n",
      "5  Sophie Ecclestone  ENG  668\n",
      "6    Katherine Brunt  ENG  646\n",
      "7     Ayabonga Khaka   SA  638\n",
      "8       Poonam Yadav  IND  617\n",
      "9       Ellyse Perry  AUS  616\n"
     ]
    }
   ],
   "source": [
    "# 6. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have toscrape:\n",
    "# i) Top 10 ODI teams in women’s cricket along with the records for matches, points andrating.\n",
    "# ii) Top 10 women’s ODI players along with the records of their team and rating.\n",
    "# iii) Top 10 women’s ODI all-rounder along with the records of their team andrating\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "page=requests.get('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "soup=BeautifulSoup(page.content)\n",
    "name=soup.find_all('span',class_=\"u-hide-phablet\")\n",
    "Name=[]\n",
    "for i in name:\n",
    "    Name.append(i.text.replace('\\n',''))\n",
    "matches=soup.find_all('td',class_=\"rankings-block__banner--matches\")\n",
    "Matches=[]\n",
    "for i in matches:\n",
    "    Matches.append(i.text.replace('\\n',''))\n",
    "points=soup.find_all('td',class_=\"rankings-block__banner--points\")\n",
    "Points=[]\n",
    "for i in points:\n",
    "    Points.append(i.text.replace('\\n',''))\n",
    "matches=soup.find_all('td',class_=\"table-body__cell u-center-text\")\n",
    "newmatch=[]\n",
    "for i in matches:\n",
    "#     for j in matches:\n",
    "    Matches.append(i.text.replace('\\n',''))\n",
    "\n",
    "# print(Matches)\n",
    "for item in range(len(Matches)):\n",
    "    if item<=0:\n",
    "        newmatch.append(Matches[item])\n",
    "        \n",
    "    elif item%2==0:\n",
    "        Points.append(Matches[item])\n",
    "    else:\n",
    "        newmatch.append(Matches[item])\n",
    "rating=soup.find_all('td',class_=\"rankings-block__banner--rating u-text-right\")\n",
    "Rating=[]\n",
    "for i in rating:\n",
    "    Rating.append(i.text.replace('\\n','').replace(' ',''))\n",
    "rating1=soup.find_all('td',class_=\"table-body__cell u-text-right rating\")\n",
    "for i in rating1:\n",
    "    Rating.append(i.text.replace('\\n',''))\n",
    "ODI_ranking=pd.DataFrame({})\n",
    "ODI_ranking['Name']=Name[:10]\n",
    "ODI_ranking['Matches']=newmatch[:10]\n",
    "ODI_ranking['Points']=Points[:10]\n",
    "ODI_ranking['Rating']=Rating[:10]\n",
    "\n",
    "print('Top 10 ODI teams in women’s cricket: \\n',ODI_ranking)\n",
    "\n",
    "# ii) Top 10 ODI Batsmen in men along with the records of their team and rating.\n",
    "menpage=requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting')\n",
    "namesoup=BeautifulSoup(menpage.content)\n",
    "name=namesoup.find_all('div',class_=\"rankings-block__banner--name-large\")\n",
    "name\n",
    "PName=[]\n",
    "for i in name:\n",
    "    PName.append(i.text.replace('\\n',''))\n",
    "PName\n",
    "name=namesoup.find_all('td',class_=\"table-body__cell rankings-table__name name\")\n",
    "for i in name:\n",
    "    for j in i('a'):\n",
    "        PName.append(j.text.replace('\\n',''))\n",
    "team=namesoup.find_all('div',class_=\"rankings-block__banner--nationality\")\n",
    "Pteam=[]\n",
    "for i in team:\n",
    "    Pteam.append(i.text.replace('\\n','').replace(' ',''))\n",
    "team=namesoup.find_all('span',class_=\"table-body__logo-text\")\n",
    "for i in team:\n",
    "    Pteam.append(i.text.replace('\\n',''))\n",
    "rank=namesoup.find_all('div',class_=\"rankings-block__banner--rating\")\n",
    "Prank=[]\n",
    "for i in rank:\n",
    "    Prank.append(i.text.replace('\\n','').replace(' ',''))\n",
    "rank=namesoup.find_all('td',class_=\"table-body__cell rating\")\n",
    "for i in rank:\n",
    "    Prank.append(i.text.replace('\\n',''))\n",
    "\n",
    "ODI_Player=pd.DataFrame({})\n",
    "ODI_Player['Name']=PName[:10]\n",
    "ODI_Player['Team']=Pteam[:10]\n",
    "ODI_Player['Rank']=Prank[:10]\n",
    "\n",
    "print('\\n\\nTop 10 ODI Batsman in women’s cricket: \\n',ODI_Player)\n",
    "\n",
    "# iii) Top 10 ODI bowlers along with the records of their team andrating.\n",
    "\n",
    "menpage=requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/bowling')\n",
    "namesoup=BeautifulSoup(menpage.content)\n",
    "name=namesoup.find_all('div',class_=\"rankings-block__banner--name-large\")\n",
    "PName=[]\n",
    "for i in name:\n",
    "    PName.append(i.text.replace('\\n',''))\n",
    "name=namesoup.find_all('td',class_=\"table-body__cell rankings-table__name name\")\n",
    "for i in name:\n",
    "    for j in i('a'):\n",
    "        PName.append(j.text.replace('\\n',''))\n",
    "team=namesoup.find_all('div',class_=\"rankings-block__banner--nationality\")\n",
    "Pteam=[]\n",
    "for i in team:\n",
    "    Pteam.append(i.text.replace('\\n','').replace(' ',''))\n",
    "team=namesoup.find_all('span',class_=\"table-body__logo-text\")\n",
    "for i in team:\n",
    "    Pteam.append(i.text.replace('\\n',''))\n",
    "rank=namesoup.find_all('div',class_=\"rankings-block__banner--rating\")\n",
    "Prank=[]\n",
    "for i in rank:\n",
    "    Prank.append(i.text.replace('\\n','').replace(' ',''))\n",
    "rank=namesoup.find_all('td',class_=\"table-body__cell rating\")\n",
    "for i in rank:\n",
    "    Prank.append(i.text.replace('\\n',''))\n",
    "\n",
    "ODI_bowler=pd.DataFrame({})\n",
    "ODI_bowler['Name']=PName[:10]\n",
    "ODI_bowler['Team']=Pteam[:10]\n",
    "ODI_bowler['Rank']=Prank[:10]\n",
    "\n",
    "print('\\n\\nTop 10 ODI Bowler in women’s cricket: \\n',ODI_bowler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c4920c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [503]>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. Write a python program to scrape details of all the mobile phones under Rs. 20,000 listed on Amazon.in. The\n",
    "# scraped data should include Product Name, Price, Image URL and Average Rating\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "page=requests.get('https://www.amazon.in/s?k=MOBILES&ref=nb_sb_noss_2')\n",
    "page\n",
    "\n",
    "# I cannot request a local url using python requests because the company's network software won't allow it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8f6180c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "             Period                         Temprature and Description\n",
      "0             Today  Widespread haze between noon and 4pm. Areas of...\n",
      "1           Tonight  Widespread haze before 4am. Mostly clear, with...\n",
      "2          Saturday  Widespread haze before 2pm. Sunny, with a high...\n",
      "3    Saturday Night  Mostly clear, with a low around 57. Breezy, wi...\n",
      "4            Sunday  Sunny, with a high near 73. Breezy, with a wes...\n",
      "5      Sunday Night      Partly cloudy, with a low around 56. Breezy. \n",
      "6            Monday                 Mostly sunny, with a high near 68.\n",
      "7      Monday Night                Mostly clear, with a low around 55.\n",
      "8           Tuesday                        Sunny, with a high near 66.\n",
      "9     Tuesday Night                Mostly clear, with a low around 54.\n",
      "10        Wednesday                        Sunny, with a high near 67.\n",
      "11  Wednesday Night               Partly cloudy, with a low around 55.\n",
      "12         Thursday                 Mostly sunny, with a high near 66.\n"
     ]
    }
   ],
   "source": [
    "# 8. Write a python program to extract information about the local weather from the National Weather Service\n",
    "# website of USA, https://www.weather.gov/ for the city, San Francisco. You need to extract data about 7 day\n",
    "# extended forecast display for the city. The data should include period, short description, temperature and\n",
    "# description\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "page=requests.get('https://forecast.weather.gov/MapClick.php?lat=37.7771&lon=-122.4196#.YSib654zaUk')\n",
    "print(page)\n",
    "\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "period=soup.find_all('div',class_=\"col-sm-2 forecast-label\")\n",
    "# print(period)\n",
    "Period=[]\n",
    "for i in period:\n",
    "  Period.append(i.text.replace('\\n',''))\n",
    "\n",
    "# print(Period)\n",
    "temp_and_description=soup.find_all('div',class_=\"col-sm-10 forecast-text\")\n",
    "Desc=[]\n",
    "for i in temp_and_description:\n",
    "  Desc.append(i.text.replace('\\n',''))\n",
    "  \n",
    "# short_desc=soup.find_all('')\n",
    "weather=pd.DataFrame({})\n",
    "weather['Period']=Period\n",
    "weather['Temprature and Description']=Desc\n",
    "\n",
    "print(weather)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "7f3cee21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Name  \\\n",
      "0                                  OMNI SPORT LEADER    \n",
      "1          Executive/Senior Executive - Partnerships    \n",
      "2                                  Executive - Sales    \n",
      "3                        Junior Operations Executive    \n",
      "4                          Student Success - Teacher    \n",
      "5                             Supply Chain Executive    \n",
      "6                                     Game Developer    \n",
      "7                       Associate - Digital Products    \n",
      "8   Program Impact In-charge (Science And Mathemat...   \n",
      "9                          Software Engineer Trainee    \n",
      "10                                   Sales Executive    \n",
      "11                       Digital Marketing Executive    \n",
      "12                           Corporate Sales Manager    \n",
      "13                                Software Developer    \n",
      "14                   Executive Assistant To Director    \n",
      "15  C++ Embedded/Semiconductor Expert (SoC Modeling)    \n",
      "16                              Mobile App Developer    \n",
      "17                                Software Developer    \n",
      "18                           Coding Teacher (Remote)    \n",
      "19                                 Validation Expert    \n",
      "20                              Full Stack Developer    \n",
      "21                    Business Development Associate    \n",
      "22         Content & E-commerce Management Executive    \n",
      "23                   Business Development Specialist    \n",
      "24             Assistant Manager - Outreach & Events    \n",
      "25              Investor Pitch Deck - Content Writer    \n",
      "26                        Full Stack Engineer (MERN)    \n",
      "27                    Business Development Executive    \n",
      "28                           Junior Graphic Designer    \n",
      "29                  Sales Development Representative    \n",
      "30                            Junior Sales Executive    \n",
      "31                            Online Coding Educator    \n",
      "32                  Executive - Statistical Modeling    \n",
      "33             Customer Experience And Sales Advisor    \n",
      "34                                 Firmware Engineer    \n",
      "35                         Junior Software Developer    \n",
      "36                               Full Stack Engineer    \n",
      "37    Backend Developer (Java/Spring Boot/Hibernate)    \n",
      "38                          Associate Content Writer    \n",
      "39                              Social Media Manager    \n",
      "\n",
      "                                             Company         CTC      Date  \n",
      "0                  DecathlonSportIndiaPrivateLimited      3-4LPA  18Sep'21  \n",
      "1         FreechargePaymentsTechnologyPrivateLimited    3-4.2LPA  11Sep'21  \n",
      "2         FreechargePaymentsTechnologyPrivateLimited    3-3.5LPA  11Sep'21  \n",
      "3         FreechargePaymentsTechnologyPrivateLimited      3-4LPA   4Sep'21  \n",
      "4                             CodeABlock(KEDTechLLC)    4-7.2LPA  25Sep'21  \n",
      "5                                          Serturner        3LPA  25Sep'21  \n",
      "6                                  CogentWebServices        3LPA  25Sep'21  \n",
      "7                                          RocSearch    3.5-4LPA  25Sep'21  \n",
      "8                                  OpenDoorEducation     6-10LPA  25Sep'21  \n",
      "9                                          Markytics      3-4LPA  25Sep'21  \n",
      "10                                        1stInClass    3-3.2LPA  25Sep'21  \n",
      "11                                       TradeVinder      3-4LPA  24Sep'21  \n",
      "12                                    FinDestination        3LPA  24Sep'21  \n",
      "13                          InnovantesITSolutionsLLP    3-3.1LPA  24Sep'21  \n",
      "14                               BestRoadwaysLimited        3LPA  24Sep'21  \n",
      "15            CircuitsutraTechnologiesPrivateLimited        6LPA  24Sep'21  \n",
      "16                                 CogentWebServices        3LPA  23Sep'21  \n",
      "17                                   SwabhavTechlabs    3-3.5LPA  23Sep'21  \n",
      "18                   CodingalEducationPrivateLimited      3-6LPA  23Sep'21  \n",
      "19                                              Apna        3LPA  23Sep'21  \n",
      "20                                         ImbueDesk      5-9LPA  23Sep'21  \n",
      "21                                          Tutedude      3-4LPA  23Sep'21  \n",
      "22                                         AnmolBaby    3-3.1LPA  23Sep'21  \n",
      "23                                      TheSmartWare        3LPA  23Sep'21  \n",
      "24                                         Formskart        3LPA  23Sep'21  \n",
      "25                                        PitchyDeck    3-4.5LPA  23Sep'21  \n",
      "26                    SoftwaySolutionsPrivateLimited    5.5-8LPA  23Sep'21  \n",
      "27                                           Volopay    3.6-5LPA  23Sep'21  \n",
      "28                HabitateTechnologiesPrivateLimited  3.2-3.6LPA  23Sep'21  \n",
      "29                                            Ziguar      4-6LPA  23Sep'21  \n",
      "30                                          Picocrew        3LPA  23Sep'21  \n",
      "31                    BrightChampsTechPrivateLimited    3-7.5LPA  23Sep'21  \n",
      "32                                    D'WellResearch    3-3.5LPA  23Sep'21  \n",
      "33                                      TilfiBanaras    3-4.8LPA  23Sep'21  \n",
      "34                       NBase2SystemsPrivateLimited        3LPA  22Sep'21  \n",
      "35  FinnovusTechnologiesPrivateLimited(CreditSiddhi)    3-3.5LPA  22Sep'21  \n",
      "36                                            Getart      4-6LPA  22Sep'21  \n",
      "37                                            Krenai  3.4-4.5LPA  22Sep'21  \n",
      "38                                         MiM-Essay    4-4.5LPA  22Sep'21  \n",
      "39                        FinvisionFinancialServices    3-3.5LPA  22Sep'21  \n"
     ]
    }
   ],
   "source": [
    "# 9. Write a python program to scrape fresher job listings from ‘https://internshala.com/’. It should include job title,\n",
    "# company name, CTC, and apply date\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "page=requests.get('https://internshala.com/fresher-jobs')\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "job_name=soup.find_all('div',class_=\"heading_4_5 profile\")\n",
    "job_title=[]\n",
    "for i in job_name:\n",
    "    job_title.append(i.text.replace('\\n',''))\n",
    "\n",
    "company_name=soup.find_all('div',class_=\"heading_6 company_name\")\n",
    "company=[]\n",
    "for i in company_name:\n",
    "    company.append(i.text.replace('\\n','').replace(' ',''))\n",
    "# print(company)\n",
    "ctc=soup.find_all('div',class_=\"item_body\")\n",
    "CTC=[]\n",
    "for i in ctc:\n",
    "    CTC.append(i.text.replace('\\n','').replace(' ',''))\n",
    "Newctc=[]\n",
    "Date=[]\n",
    "for i in range(len(CTC)):\n",
    "    if i%3==0:\n",
    "        pass\n",
    "    elif i%3==1:\n",
    "        Newctc.append(CTC[i])\n",
    "    else:\n",
    "        Date.append(CTC[i])\n",
    "Job_list=pd.DataFrame({})\n",
    "Job_list['Name']=job_title\n",
    "Job_list['Company']=company\n",
    "Job_list['CTC']=Newctc\n",
    "Job_list['Date']=Date\n",
    "\n",
    "print(Job_list)\n",
    "Job_list.to_excel('job.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a137c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "                                                                                              Address  \\\n",
      "Title                                                                                                   \n",
      "2 BHK Apartment  For Sale  In Soba Garden In Ko...  Soba Garden  Near Mahatma Society, Kothrud, Pu...   \n",
      "3 BHK Flat  For Sale  In Shivtara Garden In Kot...      New DP road,Near Badhai Sweets,Kothrud,411038   \n",
      "2 BHK Flat  For Sale  In Silver Crest Society, ...  Shivtirthanagar, Shivthirth Nagar, Kothrud, Pu...   \n",
      "3 BHK Apartment  For Sale  In Vastushree Pearl ...  Vastushree Pearl  Paud Road , Near Kinara Hote...   \n",
      "2 BHK Apartment  For Sale  In Kumar Parisar In ...  Kumar Parisar  Kothrud, Pune, Maharashtra, IND...   \n",
      "3 BHK Flat  For Sale  In Soba Garden In Kothrud     Near Mahatma Society, Kothrud, Pune 411038, Ma...   \n",
      "2 BHK Flat  For Sale  In Sudarshan Park In Koth...  4 - ka Sudarshan park,Right Paud Rd, Bhusari C...   \n",
      "4+ BHK In Independent House  For Sale  In   Kot...  Independent House,  Suraj Nagar Rd, near  Swea...   \n",
      "2 BHK Flat  For Sale  In Ashish Plaza In Kothrud    Ashish Plaza, DP Rd, Shastri Nagar, Kothrud, P...   \n",
      "1 BHK Flat  For Sale  In Narayani Apartment In ...                         Paud Rd Near  Anand Garage   \n",
      "\n",
      "                                                          Area  \\\n",
      "Title                                                            \n",
      "2 BHK Apartment  For Sale  In Soba Garden In Ko...    870 sqft   \n",
      "3 BHK Flat  For Sale  In Shivtara Garden In Kot...  1,500 sqft   \n",
      "2 BHK Flat  For Sale  In Silver Crest Society, ...  1,013 sqft   \n",
      "3 BHK Apartment  For Sale  In Vastushree Pearl ...  1,515 sqft   \n",
      "2 BHK Apartment  For Sale  In Kumar Parisar In ...  1,050 sqft   \n",
      "3 BHK Flat  For Sale  In Soba Garden In Kothrud     1,351 sqft   \n",
      "2 BHK Flat  For Sale  In Sudarshan Park In Koth...    900 sqft   \n",
      "4+ BHK In Independent House  For Sale  In   Kot...  2,600 sqft   \n",
      "2 BHK Flat  For Sale  In Ashish Plaza In Kothrud      735 sqft   \n",
      "1 BHK Flat  For Sale  In Narayani Apartment In ...    610 sqft   \n",
      "\n",
      "                                                                 EMI  \\\n",
      "Title                                                                  \n",
      "2 BHK Apartment  For Sale  In Soba Garden In Ko...     ₹55,021/Month   \n",
      "3 BHK Flat  For Sale  In Shivtara Garden In Kot...     ₹94,568/Month   \n",
      "2 BHK Flat  For Sale  In Silver Crest Society, ...     ₹54,448/Month   \n",
      "3 BHK Apartment  For Sale  In Vastushree Pearl ...     ₹91,703/Month   \n",
      "2 BHK Apartment  For Sale  In Kumar Parisar In ...     ₹81,959/Month   \n",
      "3 BHK Flat  For Sale  In Soba Garden In Kothrud        ₹80,240/Month   \n",
      "2 BHK Flat  For Sale  In Sudarshan Park In Koth...     ₹48,144/Month   \n",
      "4+ BHK In Independent House  For Sale  In   Kot...  ₹1.49 Lacs/Month   \n",
      "2 BHK Flat  For Sale  In Ashish Plaza In Kothrud       ₹41,839/Month   \n",
      "1 BHK Flat  For Sale  In Narayani Apartment In ...     ₹37,254/Month   \n",
      "\n",
      "                                                           Price  \n",
      "Title                                                             \n",
      "2 BHK Apartment  For Sale  In Soba Garden In Ko...      ₹96 Lacs  \n",
      "3 BHK Flat  For Sale  In Shivtara Garden In Kot...  ₹1.65 Crores  \n",
      "2 BHK Flat  For Sale  In Silver Crest Society, ...      ₹95 Lacs  \n",
      "3 BHK Apartment  For Sale  In Vastushree Pearl ...   ₹1.6 Crores  \n",
      "2 BHK Apartment  For Sale  In Kumar Parisar In ...  ₹1.43 Crores  \n",
      "3 BHK Flat  For Sale  In Soba Garden In Kothrud      ₹1.4 Crores  \n",
      "2 BHK Flat  For Sale  In Sudarshan Park In Koth...      ₹84 Lacs  \n",
      "4+ BHK In Independent House  For Sale  In   Kot...   ₹2.6 Crores  \n",
      "2 BHK Flat  For Sale  In Ashish Plaza In Kothrud        ₹73 Lacs  \n",
      "1 BHK Flat  For Sale  In Narayani Apartment In ...      ₹65 Lacs  \n"
     ]
    }
   ],
   "source": [
    "# 10. Write a python program to scrape house details from https://www.nobroker.in/ for any location. It should\n",
    "# include house title, location, area, emi and price\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "page=requests.get('https://www.nobroker.in/property/sale/pune/Kothrud/?searchParam=W3sibGF0IjoxOC41MDczNTE0LCJsb24iOjczLjgwNzY1NDMsInBsYWNlSWQiOiJDaElKbllTdk1yZV93anNSOEVULXMwaUxCOVEiLCJwbGFjZU5hbWUiOiJLb3RocnVkIiwic2hvd01hcCI6ZmFsc2V9XQ==')\n",
    "print(page)\n",
    "\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "title=soup.find_all('h2',class_=\"heading-6 font-semi-bold nb__1AShY\")\n",
    "# print(period)\n",
    "House_title=[]\n",
    "for i in title:\n",
    "  House_title.append(i.text.replace('\\n',''))\n",
    "\n",
    "# print(*House_title,sep='\\n\\n')\n",
    "address=soup.find_all('div',class_=\"nb__2CMjv\")\n",
    "Address=[]\n",
    "for i in address:\n",
    "  Address.append(i.text.replace('\\n',''))\n",
    "  \n",
    "area=soup.find_all('div',class_=\"nb__3oNyC\")\n",
    "Area=[]\n",
    "for i in area:\n",
    "  Area.append(i.text.replace('\\n',''))\n",
    "  \n",
    "emi=soup.find_all('div',class_=\"font-semi-bold heading-6\",id=\"roomType\")\n",
    "EMI=[]\n",
    "for i in emi:\n",
    "  EMI.append(i.text.replace('\\n',''))\n",
    "\n",
    "price=soup.find_all('div',class_=\"font-semi-bold heading-6\")\n",
    "Price=[]\n",
    "for i in price:\n",
    "    Price.append(i.text.replace('\\n',''))\n",
    "PRICE=[]\n",
    "for i in range(len(Price)):\n",
    "    if i%3==2:\n",
    "        PRICE.append(Price[i])\n",
    "        \n",
    "short_desc=soup.find_all('')\n",
    "House=pd.DataFrame({})\n",
    "House['Title']=House_title\n",
    "House['Address']=Address\n",
    "House['Area']=Area\n",
    "House['EMI']=EMI\n",
    "House['Price']=PRICE\n",
    "HOUSE=House.set_index('Title')\n",
    "print(HOUSE)\n",
    "# print(len(EMI))\n",
    "HOUSE.to_excel('house.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969f28c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
